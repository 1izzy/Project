{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "82fd6f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DistanceMetric' from 'sklearn.metrics' (C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11656/1040230740.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# from imblearn.over_sampling import SMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mOkt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOkt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\"\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_spectral\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspectral_clustering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_mean_shift\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_shift\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMeanShift\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimate_bandwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_bin_seeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_affinity_propagation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maffinity_propagation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAffinityPropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_spectral.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpairwise_kernels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkneighbors_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspectral_embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_kmeans\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mk_means\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_ball_tree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_kd_tree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKDTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_distance_metric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDistanceMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkneighbors_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius_neighbors_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsTransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRadiusNeighborsTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_distance_metric.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDistanceMetric\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_DistanceMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DistanceMetric' from 'sklearn.metrics' (C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from konlpy.tag import  Okt\n",
    "from sklearn.cluster import DBSCAN\n",
    "okt=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "4e9abc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "naver=pd.read_csv('네이버페이_전처리.csv')\n",
    "kakao=pd.read_csv('카카오페이_전처리.csv')\n",
    "samsung=pd.read_csv('삼성페이_전처리.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f83621e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kakao=kakao.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "071acbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 행 추출\n",
    "naver=naver[['STAR','cleaning_REVIEW']]\n",
    "kakao=kakao[['STAR','cleaning_REVIEW']]\n",
    "samsung=samsung[['STAR','cleaning_REVIEW']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "13b41a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_filtering(text): \n",
    "    pos_word_list = okt.pos(text, stem = True) #원형으로\n",
    "    pos_list = ['Noun'] #명사 추출\n",
    "    pos_filtered_word_list = []\n",
    "\n",
    "    for word, pos in pos_word_list: # 품사필터링\n",
    "        if pos in pos_list:\n",
    "            pos_filtered_word_list.append(word)\n",
    "\n",
    "    return pos_filtered_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "26e7d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#명사토큰화\n",
    "kakao['token_REVIEW']=kakao.cleaning_REVIEW.map(lambda x : pos_filtering(x))\n",
    "samsung['token_REVIEW']=samsung.cleaning_REVIEW.map(lambda x : pos_filtering(x))\n",
    "naver['token_REVIEW']=naver.cleaning_REVIEW.map(lambda x : pos_filtering(x))\n",
    "\n",
    "#한글자 지우기\n",
    "kakao['token_REVIEW'] = kakao['token_REVIEW'].map(lambda x :[word for word in x if len(word) != 1])\n",
    "samsung['token_REVIEW'] = samsung['token_REVIEW'].map(lambda x :[word for word in x if len(word) != 1])\n",
    "naver['token_REVIEW'] = naver['token_REVIEW'].map(lambda x :[word for word in x if len(word) != 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "b563b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#감성 라벨링 (1~3 => 0; 4~5 => 1)\n",
    "naver.STAR=naver.STAR.apply(lambda x : 1 if x>3 else 0)\n",
    "kakao.STAR=kakao.STAR.apply(lambda x : 1 if x>3 else 0)\n",
    "samsung.STAR=samsung.STAR.apply(lambda x : 1 if x>3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f7c21747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#리스트빈것지우기\n",
    "naver['token_REVIEW']=naver['token_REVIEW'].apply( lambda x : \"\" if x==[] else x)\n",
    "samsung['token_REVIEW']=samsung['token_REVIEW'].apply( lambda x : \"\" if x==[] else x)\n",
    "kakao['token_REVIEW']=kakao['token_REVIEW'].apply( lambda x : \"\" if x==[] else x)\n",
    "naver=naver[naver.token_REVIEW!=\"\"]\n",
    "samsung=samsung[samsung.token_REVIEW!=\"\"]\n",
    "kakao=kakao[kakao.token_REVIEW!=\"\"]\n",
    "naver.reset_index(drop=True,inplace=True)\n",
    "samsung.reset_index(drop=True,inplace=True)\n",
    "kakao.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "5525338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #str => 리스트 타입 변환\n",
    "# naver.token_REVIEW=naver.token_REVIEW.apply(lambda x: eval(\"\".join(x)))\n",
    "# samsung.token_REVIEW=samsung.token_REVIEW.apply(lambda x: eval(\"\".join(x)))\n",
    "# kakao.token_REVIEW=kakao.token_REVIEW.apply(lambda x: eval(\"\".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "89300daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "naver.token_REVIEW=naver.token_REVIEW.apply(lambda x: \" \".join(x))\n",
    "samsung.token_REVIEW=samsung.token_REVIEW.apply(lambda x: \" \".join(x))\n",
    "kakao.token_REVIEW=kakao.token_REVIEW.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4374ad",
   "metadata": {},
   "source": [
    "## 네이버 긍부정단어 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e58d0a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    309\n",
       "0    267\n",
       "Name: STAR, dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver.STAR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e41ffef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 스플릿 (네이버는 양이 적어 8:2로 분리)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(naver.token_REVIEW, naver.STAR, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "83d32f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼파라미터 :{'C': 5}, 정확도 :0.696\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "vectorizer = TfidfVectorizer(min_df=1, norm='l2', ngram_range=(1,1))\n",
    "train_features = vectorizer.fit_transform(train_texts)\n",
    "#최적모델찾기\n",
    "clf = LogisticRegression(random_state=0)\n",
    "params = {\"C\":[0.1,0.5,1,5,10]}\n",
    "model= GridSearchCV(clf, param_grid=params, cv = 5, scoring='accuracy') #그리드서치로 돌리면 계수안나옴\n",
    "model.fit(train_features, train_labels)\n",
    "print('최적 하이퍼파라미터 :{0}, 정확도 :{1:.3f}'.format(model.best_params_,model.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c6e884c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "51161e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘못 분류된 강의평: 28 out of 116\n",
      "Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_features, train_labels)\n",
    "test_features = vectorizer.transform(test_texts)\n",
    "pred_labels = model.predict(test_features)\n",
    "print('잘못 분류된 강의평: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b804fe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추가 (3.035)\n",
      "워치 (2.837)\n",
      "자산 (2.433)\n",
      "애플 (2.369)\n",
      "연동 (2.308)\n",
      "정말 (2.215)\n",
      "자주 (1.834)\n",
      "아주 (1.792)\n",
      "편의점 (1.679)\n",
      "그동안 (1.630)\n",
      "쓰기 (1.527)\n",
      "사용 (1.520)\n",
      "별도 (1.465)\n",
      "결제 (1.407)\n",
      "올해 (1.396)\n",
      "강추 (1.391)\n",
      "얼룬해주세욤 (1.379)\n",
      "재미 (1.331)\n",
      "제일 (1.323)\n",
      "방식 (1.322)\n",
      "통신 (1.321)\n",
      "플레이스토어 (1.309)\n",
      "비교 (1.293)\n",
      "소액 (1.281)\n",
      "무료 (1.253)\n",
      "버그 (1.235)\n",
      "평소 (1.234)\n",
      "대박 (1.232)\n",
      "배송 (1.230)\n",
      "위젯 (1.229)\n",
      "이미지 (1.220)\n",
      "디자인 (1.210)\n",
      "기대 (1.207)\n",
      "알뜰 (1.162)\n",
      "주시 (1.159)\n",
      "공감 (1.159)\n",
      "굿굿 (1.159)\n",
      "굿굿굿 (1.159)\n",
      "기분 (1.159)\n",
      "따끈따끈 (1.159)\n",
      "아침 (1.159)\n",
      "원조 (1.159)\n",
      "제목 (1.159)\n",
      "캐뱅추갖 (1.159)\n",
      "한지 (1.159)\n",
      "네퍼 (1.141)\n",
      "저번 (1.140)\n",
      "포인트 (1.132)\n",
      "최고 (1.124)\n",
      "멤버십 (1.077)\n",
      "문의 (-1.127)\n",
      "제대로 (-1.133)\n",
      "요청 (-1.139)\n",
      "신용 (-1.154)\n",
      "다이소 (-1.160)\n",
      "개선 (-1.182)\n",
      "거래 (-1.192)\n",
      "게이 (-1.196)\n",
      "금액 (-1.206)\n",
      "장바구니 (-1.212)\n",
      "어찌 (-1.216)\n",
      "다시 (-1.219)\n",
      "업데이트 (-1.232)\n",
      "어플 (-1.247)\n",
      "씨유 (-1.271)\n",
      "시작 (-1.277)\n",
      "이상 (-1.293)\n",
      "위치 (-1.293)\n",
      "로뱅 (-1.297)\n",
      "가입 (-1.354)\n",
      "반복 (-1.376)\n",
      "뭔가 (-1.430)\n",
      "다운로드 (-1.436)\n",
      "삭제 (-1.502)\n",
      "투명 (-1.534)\n",
      "이유 (-1.542)\n",
      "아이디 (-1.566)\n",
      "정보 (-1.573)\n",
      "한번 (-1.588)\n",
      "은행 (-1.596)\n",
      "편의 (-1.613)\n",
      "고객 (-1.763)\n",
      "로그인 (-1.789)\n",
      "주심 (-1.804)\n",
      "인식 (-1.846)\n",
      "문상 (-1.885)\n",
      "하나요 (-1.906)\n",
      "본인 (-1.920)\n",
      "로딩 (-1.946)\n",
      "현장 (-2.033)\n",
      "종료 (-2.049)\n",
      "수가 (-2.070)\n",
      "설치 (-2.091)\n",
      "번호 (-2.102)\n",
      "인증서 (-2.157)\n",
      "코드 (-2.224)\n",
      "전환 (-2.300)\n",
      "시도 (-2.571)\n",
      "인증 (-2.736)\n",
      "그냥 (-3.023)\n"
     ]
    }
   ],
   "source": [
    "coefficients = model.coef_.tolist()\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "vocablist = [word for word, _ in sorted(vectorizer.vocabulary_.items(), key=lambda x:x[1])]\n",
    "#긍부정단어\n",
    "for word, coef in sorted_coefficients[:50]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))\n",
    "for word, coef in sorted_coefficients[-50:]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef073c",
   "metadata": {},
   "source": [
    "## 카카오 긍부정 단어 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d4dc499e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1733\n",
       "1    1276\n",
       "Name: STAR, dtype: int64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kakao.STAR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ebe70346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 스플릿 \n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(kakao.token_REVIEW, kakao.STAR, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "f02f1c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼파라미터 :{'C': 1}, 정확도 :0.777\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "vectorizer = TfidfVectorizer(min_df=1, norm='l2', ngram_range=(1,1))\n",
    "train_features = vectorizer.fit_transform(train_texts)\n",
    "#최적모델찾기\n",
    "clf = LogisticRegression(random_state=0)\n",
    "params = {\"C\":[0.1,0.5,1,5,10]}\n",
    "model= GridSearchCV(clf, param_grid=params, cv = 5, scoring='accuracy') \n",
    "model.fit(train_features, train_labels)\n",
    "print('최적 하이퍼파라미터 :{0}, 정확도 :{1:.3f}'.format(model.best_params_,model.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "338f574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "48c3fb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘못 분류된 강의평: 190 out of 903\n",
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_features, train_labels)\n",
    "test_features = vectorizer.transform(test_texts)\n",
    "pred_labels = model.predict(test_features)\n",
    "print('잘못 분류된 강의평: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "67a6a2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당첨 (2.544)\n",
      "최고 (2.493)\n",
      "아주 (2.443)\n",
      "추가 (1.876)\n",
      "굿굿 (1.865)\n",
      "감사 (1.789)\n",
      "대박 (1.749)\n",
      "이벤트 (1.720)\n",
      "정말 (1.699)\n",
      "사용 (1.313)\n",
      "기분 (1.285)\n",
      "조금 (1.242)\n",
      "와우 (1.236)\n",
      "행운 (1.205)\n",
      "쓰기 (1.185)\n",
      "럭키 (1.133)\n",
      "재미 (1.109)\n",
      "실용 (0.995)\n",
      "기대 (0.956)\n",
      "이번 (0.924)\n",
      "모든 (0.871)\n",
      "항상 (0.868)\n",
      "무지 (0.865)\n",
      "원조 (0.865)\n",
      "자주 (0.863)\n",
      "추천 (0.839)\n",
      "단위 (0.832)\n",
      "만족 (0.776)\n",
      "변경 (0.773)\n",
      "세상 (0.764)\n",
      "신속 (0.764)\n",
      "저번 (0.744)\n",
      "가지 (0.717)\n",
      "금융 (0.697)\n",
      "보기 (0.692)\n",
      "이용 (0.683)\n",
      "재부팅 (0.681)\n",
      "굿굿굿 (0.677)\n",
      "생활 (0.667)\n",
      "활용 (0.663)\n",
      "오당 (0.663)\n",
      "이벤 (0.663)\n",
      "체고 (0.663)\n",
      "헤헤 (0.663)\n",
      "난리 (0.649)\n",
      "미국 (0.624)\n",
      "득템 (0.622)\n",
      "도움 (0.622)\n",
      "무료 (0.610)\n",
      "혜택 (0.593)\n",
      "회사 (-0.885)\n",
      "이상 (-0.924)\n",
      "토스 (-0.925)\n",
      "고객 (-0.926)\n",
      "환불 (-0.949)\n",
      "인증서 (-0.955)\n",
      "페미 (-0.957)\n",
      "다른 (-0.959)\n",
      "설치 (-0.969)\n",
      "대체 (-0.996)\n",
      "하나요 (-0.999)\n",
      "조회 (-1.011)\n",
      "다운로드 (-1.046)\n",
      "카톡 (-1.046)\n",
      "촬영 (-1.052)\n",
      "증권 (-1.085)\n",
      "에러 (-1.086)\n",
      "이후 (-1.093)\n",
      "먹통 (-1.094)\n",
      "문제 (-1.103)\n",
      "거지 (-1.106)\n",
      "실행 (-1.112)\n",
      "비밀번호 (-1.117)\n",
      "이유 (-1.119)\n",
      "하라 (-1.121)\n",
      "제대로 (-1.127)\n",
      "도대체 (-1.145)\n",
      "입력 (-1.180)\n",
      "출금 (-1.234)\n",
      "삭제 (-1.360)\n",
      "네이버 (-1.373)\n",
      "금고 (-1.390)\n",
      "탈퇴 (-1.418)\n",
      "소리 (-1.455)\n",
      "최악 (-1.457)\n",
      "자꾸 (-1.458)\n",
      "업데이트 (-1.464)\n",
      "민증 (-1.491)\n",
      "시간 (-1.531)\n",
      "무슨 (-1.532)\n",
      "갑자기 (-1.586)\n",
      "해지 (-1.632)\n",
      "쓰레기 (-1.638)\n",
      "어디 (-1.643)\n",
      "짜증 (-1.689)\n",
      "연결 (-1.919)\n",
      "계속 (-2.039)\n",
      "인증 (-2.063)\n",
      "오류 (-2.064)\n",
      "로그인 (-2.586)\n"
     ]
    }
   ],
   "source": [
    "coefficients = model.coef_.tolist()\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "vocablist = [word for word, _ in sorted(vectorizer.vocabulary_.items(), key=lambda x:x[1])]\n",
    "#긍부정단어\n",
    "for word, coef in sorted_coefficients[:50]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))\n",
    "for word, coef in sorted_coefficients[-50:]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c3f9b",
   "metadata": {},
   "source": [
    "## 삼성 긍부정단어 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "23749092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    21316\n",
       "0     1853\n",
       "Name: STAR, dtype: int64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samsung.STAR.value_counts() #데이터불균형.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9cb48d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 스플릿 \n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(samsung.token_REVIEW, samsung.STAR, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f791d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=0)\n",
    "train_texts, train_labels = smote.fit_sample(train_texts, train_labels)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트:', X_train_over.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "da5afe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼파라미터 :{'C': 5}, 정확도 :0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "vectorizer = TfidfVectorizer(min_df=1, norm='l2', ngram_range=(1,1))\n",
    "train_features = vectorizer.fit_transform(train_texts)\n",
    "#최적모델찾기\n",
    "clf = LogisticRegression(random_state=0)\n",
    "params = {\"C\":[0.1,0.5,1,5,10]}\n",
    "model= GridSearchCV(clf, param_grid=params, cv = 5, scoring='accuracy') \n",
    "model.fit(train_features, train_labels)\n",
    "print('최적 하이퍼파라미터 :{0}, 정확도 :{1:.3f}'.format(model.best_params_,model.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "b8ea353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f2d024d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘못 분류된 강의평: 398 out of 6951\n",
      "Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_features, train_labels)\n",
    "test_features = vectorizer.transform(test_texts)\n",
    "pred_labels = model.predict(test_features)\n",
    "print('잘못 분류된 강의평: {} out of {}'.format((pred_labels != test_labels).sum(),len(test_labels)))\n",
    "print('Accuracy: %.2f' % accuracy_score(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2e1ab309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고 (5.925)\n",
      "다만 (4.668)\n",
      "매우 (3.761)\n",
      "지갑 (3.544)\n",
      "굿굿 (3.156)\n",
      "개편 (3.116)\n",
      "아주 (3.080)\n",
      "신세계 (3.071)\n",
      "역시 (3.067)\n",
      "정말 (2.719)\n",
      "아이폰 (2.648)\n",
      "항상 (2.426)\n",
      "출근 (2.320)\n",
      "적립 (2.265)\n",
      "만족 (2.255)\n",
      "뱅크 (2.226)\n",
      "인터넷 (2.212)\n",
      "굿굿굿 (2.198)\n",
      "가스 (2.182)\n",
      "시스템 (2.167)\n",
      "걱정 (2.135)\n",
      "생활 (2.117)\n",
      "편의 (2.116)\n",
      "필수 (2.093)\n",
      "서나 (2.007)\n",
      "개꿀 (2.001)\n",
      "남편 (1.984)\n",
      "번만 (1.945)\n",
      "기간 (1.912)\n",
      "사용 (1.879)\n",
      "베리 (1.877)\n",
      "최고다 (1.868)\n",
      "강종 (1.866)\n",
      "단점 (1.864)\n",
      "가장 (1.836)\n",
      "하나로 (1.807)\n",
      "추천 (1.800)\n",
      "만사 (1.797)\n",
      "점빼 (1.778)\n",
      "금융 (1.766)\n",
      "혁신 (1.750)\n",
      "전반 (1.743)\n",
      "혁명 (1.706)\n",
      "별개 (1.639)\n",
      "외출 (1.636)\n",
      "모바일 (1.596)\n",
      "조음 (1.594)\n",
      "더욱 (1.593)\n",
      "아우 (1.576)\n",
      "소지 (1.573)\n",
      "오류로 (-2.904)\n",
      "점심시간 (-2.923)\n",
      "방법 (-2.926)\n",
      "회비 (-2.954)\n",
      "별로 (-2.995)\n",
      "데이터 (-3.006)\n",
      "계정 (-3.021)\n",
      "만기 (-3.023)\n",
      "아씨 (-3.029)\n",
      "초기 (-3.069)\n",
      "폴드 (-3.071)\n",
      "오류 (-3.089)\n",
      "기본 (-3.089)\n",
      "미만 (-3.104)\n",
      "보지 (-3.111)\n",
      "정리 (-3.122)\n",
      "수준 (-3.136)\n",
      "재부팅 (-3.179)\n",
      "도대체 (-3.212)\n",
      "통신사 (-3.238)\n",
      "비밀번호 (-3.263)\n",
      "광고 (-3.269)\n",
      "건가 (-3.293)\n",
      "전화번호 (-3.301)\n",
      "금융기관 (-3.350)\n",
      "준비 (-3.431)\n",
      "개판 (-3.432)\n",
      "며칠 (-3.479)\n",
      "해제 (-3.499)\n",
      "종일 (-3.521)\n",
      "극협 (-3.523)\n",
      "연결 (-3.547)\n",
      "교통카드 (-3.553)\n",
      "공지 (-3.612)\n",
      "로딩 (-3.816)\n",
      "어쩌 (-3.873)\n",
      "점검 (-3.888)\n",
      "어제 (-3.944)\n",
      "삭제 (-3.966)\n",
      "진행 (-4.033)\n",
      "짜증 (-4.062)\n",
      "먹통 (-4.104)\n",
      "쓰레기 (-4.156)\n",
      "제발 (-4.214)\n",
      "구림 (-4.229)\n",
      "업데이트 (-4.239)\n",
      "아예 (-4.253)\n",
      "자꾸 (-4.334)\n",
      "최악 (-4.798)\n",
      "갑자기 (-6.529)\n"
     ]
    }
   ],
   "source": [
    "coefficients = model.coef_.tolist()\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "vocablist = [word for word, _ in sorted(vectorizer.vocabulary_.items(), key=lambda x:x[1])]\n",
    "#긍부정단어\n",
    "for word, coef in sorted_coefficients[:50]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))\n",
    "for word, coef in sorted_coefficients[-50:]:\n",
    "    print('{0:} ({1:.3f})'.format(vocablist[word], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf34ab",
   "metadata": {},
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ed745",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 5, ngram_range=(1,5))\n",
    "tfidf_vectorizer.fit(naver.token_REVIEW)\n",
    "vector = tfidf_vectorizer.transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "084fe7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAR</th>\n",
       "      <th>cleaning_REVIEW</th>\n",
       "      <th>token_REVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>주민득록증이 없는데 어떻게 민증을 발급기간을 입력하라는 건지</td>\n",
       "      <td>주민 득록증 민증 발급 기간 입력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>페이 중에는 최고인 듯</td>\n",
       "      <td>페이 최고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>지문 변경한 적 없는데 지문 변경됐다고 재등록하라고 나와요 그래서 재등록 계속하는데...</td>\n",
       "      <td>지문 변경 지문 변경 등록 등록 계속 비번 입력 지문 확인 단계 무한 지문 등록 아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>비밀 최형욱 성 선정</td>\n",
       "      <td>비밀 최형욱 선정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>좋으나 아쉬운 점이 페이를 충전하려면 최소금액이 만 원 이상인 것이 좀 불편하다 천...</td>\n",
       "      <td>페이 충전 최소 금액 이상인 오천 정도 최소 충전 금액</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>0</td>\n",
       "      <td>계좌조회하는데 걸리는 시간이 분은 걸리는데 그거 기다릴 사람이 몇이나 될까요 업데이...</td>\n",
       "      <td>계좌 조회 시간 그거 사람 업데이트 메시지 짜증 점도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>0</td>\n",
       "      <td>써보지도 못해요 만세부터 사용 가능하네요 만세로 바꿔주시면 좋을 것 같아요 생일이 ...</td>\n",
       "      <td>보지 만세 사용 만세 생일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>1</td>\n",
       "      <td>진짜 엄청 좋음 카카오뱅크보다 더 좋음</td>\n",
       "      <td>진짜 카카오 뱅크</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>0</td>\n",
       "      <td>오프라인에서 지원할 수 있는 카드 중에서 우리카드도 추가해주세요 카드 등록했더니 오...</td>\n",
       "      <td>오프라인 지원 카드 우리카드 추가 카드 등록 오프라인 미지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>0</td>\n",
       "      <td>결제하면 자동으로 리워드 줬으면 좋겠어요 매번 도 안되는 돈 받으려고 카톡 열어서 ...</td>\n",
       "      <td>결제 자동 워드 매번 카톡 통신 장애 오류 다시 짜증 마치 어서 정말 카카오 페이 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3009 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STAR                                    cleaning_REVIEW  \\\n",
       "0        0                  주민득록증이 없는데 어떻게 민증을 발급기간을 입력하라는 건지   \n",
       "1        1                                       페이 중에는 최고인 듯   \n",
       "2        0  지문 변경한 적 없는데 지문 변경됐다고 재등록하라고 나와요 그래서 재등록 계속하는데...   \n",
       "3        0                                        비밀 최형욱 성 선정   \n",
       "4        0  좋으나 아쉬운 점이 페이를 충전하려면 최소금액이 만 원 이상인 것이 좀 불편하다 천...   \n",
       "...    ...                                                ...   \n",
       "3004     0  계좌조회하는데 걸리는 시간이 분은 걸리는데 그거 기다릴 사람이 몇이나 될까요 업데이...   \n",
       "3005     0  써보지도 못해요 만세부터 사용 가능하네요 만세로 바꿔주시면 좋을 것 같아요 생일이 ...   \n",
       "3006     1                              진짜 엄청 좋음 카카오뱅크보다 더 좋음   \n",
       "3007     0  오프라인에서 지원할 수 있는 카드 중에서 우리카드도 추가해주세요 카드 등록했더니 오...   \n",
       "3008     0  결제하면 자동으로 리워드 줬으면 좋겠어요 매번 도 안되는 돈 받으려고 카톡 열어서 ...   \n",
       "\n",
       "                                           token_REVIEW  \n",
       "0                                    주민 득록증 민증 발급 기간 입력  \n",
       "1                                                 페이 최고  \n",
       "2     지문 변경 지문 변경 등록 등록 계속 비번 입력 지문 확인 단계 무한 지문 등록 아...  \n",
       "3                                             비밀 최형욱 선정  \n",
       "4                        페이 충전 최소 금액 이상인 오천 정도 최소 충전 금액  \n",
       "...                                                 ...  \n",
       "3004                      계좌 조회 시간 그거 사람 업데이트 메시지 짜증 점도  \n",
       "3005                                     보지 만세 사용 만세 생일  \n",
       "3006                                          진짜 카카오 뱅크  \n",
       "3007                   오프라인 지원 카드 우리카드 추가 카드 등록 오프라인 미지  \n",
       "3008  결제 자동 워드 매번 카톡 통신 장애 오류 다시 짜증 마치 어서 정말 카카오 페이 ...  \n",
       "\n",
       "[3009 rows x 3 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kakao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7b056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
